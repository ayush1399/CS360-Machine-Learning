{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS360-Assignment3",
      "provenance": [],
      "authorship_tag": "ABX9TyOVxcsEhvEc3r/VD/LgP5Qt"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3Gg7DvqhWLr",
        "colab_type": "text"
      },
      "source": [
        "#ML Lab (CS360)\n",
        "##Assignment 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLEO77hv2_MY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRjaz4zW4BAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model():\n",
        "  def __init__(self, p):\n",
        "    self._features = p\n",
        "    self._bias = 1\n",
        "    self._weights = np.random.uniform(size=(p, 1))\n",
        "\n",
        "  def predict(self, X):\n",
        "    array_1d = lambda x: np.reshape(x, newshape=(-1))\n",
        "\n",
        "    if type(X).__name__ == 'list' or type(X).__name__ == 'int' or type(X).__name__ == 'float':\n",
        "      X = np.array(X)\n",
        "\n",
        "    if X.ndim == 0:\n",
        "      if self._features > 1:\n",
        "        raise (f\"Number of features of sample must be {self._features}\")\n",
        "      else:\n",
        "        return array_1d(np.dot(X, self._weights) + self._bias)\n",
        "\n",
        "    elif X.ndim == 1:\n",
        "      if X.shape[0] == self._features or X.ndim == self._features:\n",
        "        return array_1d(self._bias + np.multiply(X, self._weights))\n",
        "      else:\n",
        "        raise Exception(f\"Number of features of sample must be {self.features}\")\n",
        "\n",
        "    elif X.ndim == 2:\n",
        "      if X.shape[1] == self._features:\n",
        "        return array_1d(np.dot(X, self._weights) + self._bias)\n",
        "      else:\n",
        "        raise Exception(f\"Shape of input array must be (Number of samples, {self._features})\")\n",
        "\n",
        "    else:\n",
        "      raise Exception(f\"Too many dimensions in input array: {X.ndim}\")\n",
        "      \n",
        "  def score(self, X, y):\n",
        "    y_preds = self.predict(X)\n",
        "    assert y_preds.shape == np.asarray(y).shape\n",
        "    return np.mean(np.absolute(np.subtract(y, y_preds)))\n",
        "\n",
        "class OLS_LinearRegression(Model):\n",
        "  def __init__(self, features):\n",
        "    Model.__init__(self, features)\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    if type(X).__name__ == 'list':\n",
        "      X = np.array(X)\n",
        "      X = np.reshape(X, reshape=(-1, 1))\n",
        "\n",
        "    if type(y).__name__ == 'list':\n",
        "      y = np.array(y).reshape(-1)\n",
        "\n",
        "    assert type(X).__name__ == 'ndarray'\n",
        "    assert X.shape[0] > self._features\n",
        "    assert X.shape[1] == self._features\n",
        "    assert X.shape[0] == y.shape[0]\n",
        "\n",
        "    X = np.c_[np.ones(X.shape[0]), X]\n",
        "    \n",
        "    pseudo_inv = np.linalg.pinv(np.dot(X.T, X))\n",
        "\n",
        "    weights = np.dot(np.dot(pseudo_inv, X.T), y)\n",
        "\n",
        "    self._bias = weights[0]\n",
        "    self._weights = weights[1:]\n",
        "\n",
        "\n",
        "class GD_LinearRegression(Model):\n",
        "  def __init__(self, features, learning_rate=1e-4):\n",
        "    self._learning_rate = learning_rate\n",
        "    Model.__init__(self, features)\n",
        "  \n",
        "  def fit(self, X, y):\n",
        "    db, dw = self.__derivatives(X, y)\n",
        "    while self.__update(db, dw, X, y):\n",
        "      db, dw = self.__derivatives(X, y)\n",
        "\n",
        "  def __cost_function(self, X, y):\n",
        "    m = X.shape[0] # number of samples\n",
        "    squared_error = np.sum(np.square(self.predict(X) - y)) / 2\n",
        "    return squared_error / m \n",
        "\n",
        "  def __derivatives(self, X, y):\n",
        "    m = X.shape[0] # number of samples\n",
        "\n",
        "    error = np.reshape(np.subtract(self.predict(X), y), newshape=(-1, 1))\n",
        "\n",
        "    del_b = np.sum(error * self._bias, axis=0) / m\n",
        "    del_w = np.reshape(np.sum(error * X, axis=0) / m, newshape=(-1, 1))\n",
        "  \n",
        "    return del_b, del_w\n",
        "  \n",
        "  def __update(self, db, dw, X, y):\n",
        "    converged = lambda J, J_new: -1e-2 < J - J_new < 1e-2\n",
        "\n",
        "    J = self.__cost_function(X, y)\n",
        "\n",
        "    self._bias -= self._learning_rate * db\n",
        "    self._weights -= self._learning_rate * dw\n",
        "\n",
        "    J_new = self.__cost_function(X, y)\n",
        "\n",
        "    return not converged(J, J_new)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goHrFbHffI_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_and_scale(X, y):\n",
        "  # Split the dataset \n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.6, random_state=44)\n",
        "  X_validation, X_test, y_validation, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=43)\n",
        "\n",
        "  # scaling the dataset\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(X_train)\n",
        "  X_train = scaler.transform(X_train)\n",
        "  X_validation = scaler.transform(X_validation)\n",
        "  X_test = scaler.transform(X_test)\n",
        "\n",
        "  return X_train, y_train, X_validation, y_validation, X_test, y_test\n",
        "\n",
        "def print_scores(regressor, X_train, y_train, X_validation, y_validation, X_test, y_test):\n",
        "  train_accuracy = regressor.score(X_train, y_train)\n",
        "  validation_accuracy = regressor.score(X_validation, y_validation)\n",
        "  test_accuracy = regressor.score(X_test, y_test)\n",
        "  print(f\"Training Set Accuracy: {train_accuracy}\\nCross-Validaton Set Accuracy: {validation_accuracy}\\nTest Set Accuracy: {test_accuracy}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqrcLWzghQ0z",
        "colab_type": "text"
      },
      "source": [
        "### Simple Linear Regression (One feature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ1J__ryhRFC",
        "colab_type": "text"
      },
      "source": [
        "1. Implement the linear regression using (a) Ordinary Least Squares (Method) and (b) Gradient Descent Algorithm.\n",
        "Dataset: Swedish Auto Insurance dataset.\n",
        "i) You need to split the dataset into train (60%), validation (20%), and test (20%).\n",
        "ii) Print the train, validation, and test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mzayBFwDGbv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the Dataset\n",
        "\n",
        "dataset = pd.read_csv('insurance_dataset.csv')\n",
        "X = dataset['X'].to_numpy().reshape(-1, 1)\n",
        "y = dataset['Y'].to_numpy()\n",
        "\n",
        "#Split the dataset into training (60%), validation (20%) and testing sets (20%)\n",
        "X_train, y_train, X_validation, y_validation, X_test, y_test = split_and_scale(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M5QvHoZDOa2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ad525ab4-9df5-4836-a1a0-3d3e6622c2f8"
      },
      "source": [
        "# Using Ordinary Least Squares Method\n",
        "\n",
        "ols_insurance = OLS_LinearRegression(X_train.shape[1])\n",
        "ols_insurance.fit(X_train, y_train)\n",
        "\n",
        "print_scores(ols_insurance, X_train, y_train, \n",
        "             X_validation, y_validation, \n",
        "             X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Set Accuracy: 26.309574984859502\n",
            "Cross-Validaton Set Accuracy: 26.037363528237435\n",
            "Test Set Accuracy: 37.1354947272296\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qcr4DC5d3sF5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "77207d29-d92d-4c2d-fcd0-ea71291f94bb"
      },
      "source": [
        "# Using Gradient Descent\n",
        "\n",
        "gd_insurance = GD_LinearRegression(X_train.shape[1], learning_rate=0.001)\n",
        "gd_insurance.fit(X_train, y_train)\n",
        "\n",
        "print_scores(gd_insurance, X_train, y_train, \n",
        "             X_validation, y_validation, \n",
        "             X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Set Accuracy: 26.099019142030517\n",
            "Cross-Validaton Set Accuracy: 26.65294991852139\n",
            "Test Set Accuracy: 37.3997186268862\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0WvT5k7kZXA",
        "colab_type": "text"
      },
      "source": [
        "###Multiple Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JleYxlBOkeow",
        "colab_type": "text"
      },
      "source": [
        "2. Implement the linear regression using the Gradient Descent Algorithm\n",
        "Dataset: Boston house pricing dataset.\n",
        "i) You need to split the dataset into train (60%), validation (20%), and test(20%).\n",
        "ii) Print the train, validation, and test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD95E0zcko7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import datasets\n",
        "boston = datasets.load_boston(return_X_y=False)\n",
        "\n",
        "X, y = boston.data, boston.target\n",
        "\n",
        "X_train, y_train, X_validation, y_validation, X_test, y_test = split_and_scale(X, y)\n",
        "\n",
        "del X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0fZ14k1Maje",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "02569709-63e7-4f3e-9b2d-6c2424d9ba65"
      },
      "source": [
        "gd_bostonhousing = GD_LinearRegression(X_train.shape[1], learning_rate=1e-3)\n",
        "gd_bostonhousing.fit(X_train, y_train)\n",
        "print_scores(gd_bostonhousing, X_train, y_train, \n",
        "             X_validation, y_validation, \n",
        "             X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Set Accuracy: 3.6234561106003276\n",
            "Cross-Validaton Set Accuracy: 3.606224847445148\n",
            "Test Set Accuracy: 4.15061633539572\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}